{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86649d28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu113\n",
      "Requirement already satisfied: torch in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (1.11.0+cu113)\n",
      "Requirement already satisfied: torchvision in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (0.12.0+cu113)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (0.11.0+cu113)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (from torch) (3.7.4.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (from torchvision) (8.2.0)\n",
      "Requirement already satisfied: requests in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (from torchvision) (2.25.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (from torchvision) (1.20.1)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (from requests->torchvision) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (from requests->torchvision) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.10)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "569e3771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (4.18.0)\n",
      "Requirement already satisfied: requests in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (from transformers) (2021.4.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (from transformers) (1.20.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (from transformers) (0.5.1)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (from transformers) (0.0.49)\n",
      "Requirement already satisfied: filelock in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: click in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: six in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "137ce131",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "from sklearn.metrics import accuracy_score , recall_score , precision_score ,f1_score\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)\n",
    "#from transformers import BertModel, BertConfig\n",
    "\n",
    "# Initializing a BERT bert-base-uncased style configuration\n",
    "#bert_configuration = BertConfig()\n",
    "\n",
    "# Initializing a model from the bert-base-uncased style configuration\n",
    "#bert_model = BertModel(bert_configuration)\n",
    "\n",
    "# Accessing the model configuration\n",
    "#bert_configuration = model.config\n",
    "\n",
    "\n",
    "#from transformers import BertModel, AutoConfig\n",
    "\n",
    "#configuration = AutoConfig.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "#configuration.hidden_dropout_prob = 0.5\n",
    "#configuration.attention_probs_dropout_prob = 0.5\n",
    "        \n",
    "#bert_model = BertModel.from_pretrained(pretrained_model_name_or_path = 'bert-base-uncased', \n",
    "#config = configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c390bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (2.1.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (from datasets) (1.20.1)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (from datasets) (4.64.0)\n",
      "Requirement already satisfied: pyarrow>=5.0.0 in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (from datasets) (7.0.0)\n",
      "Requirement already satisfied: responses<0.19 in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (from datasets) (0.70.12.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (from datasets) (20.9)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (from datasets) (0.5.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (from datasets) (2022.3.0)\n",
      "Requirement already satisfied: dill in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (from datasets) (0.3.4)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (from datasets) (3.8.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (from datasets) (1.2.4)\n",
      "Requirement already satisfied: xxhash in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (from datasets) (3.0.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (from datasets) (2.25.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.0.12)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (5.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (from packaging->datasets) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (2.10)\n",
      "Requirement already satisfied: colorama in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (20.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.7.2)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (2.0.12)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (from pandas->datasets) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ddey4\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf27c8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b85a8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "CleanedData= pd.read_csv('C:/Users/ddey4/Downloads/archive/Cleaned_Youtube.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "472ab1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "ActualData = CleanedData[['No Punc Title','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b000b69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No Punc Title</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>we want to talk about our marriage</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the trump presidency last week tonight with jo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>racist superman | rudy mancuso king bach  lele...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nickelback lyrics real or fake</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2 weeks with iphone x</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64188</th>\n",
       "      <td>cyberpunk 2077 story open world and firstperso...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64189</th>\n",
       "      <td>masterchef | standup comedy by karunesh talwar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64190</th>\n",
       "      <td>how2 how to solve a mystery</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64191</th>\n",
       "      <td>kingdom hearts iii – square enix e3 showcase 2...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64192</th>\n",
       "      <td>trump advisor grovels to trudeau</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64193 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           No Punc Title  label\n",
       "0                     we want to talk about our marriage      1\n",
       "1      the trump presidency last week tonight with jo...      1\n",
       "2      racist superman | rudy mancuso king bach  lele...      1\n",
       "3                         nickelback lyrics real or fake      0\n",
       "4                                  2 weeks with iphone x      0\n",
       "...                                                  ...    ...\n",
       "64188  cyberpunk 2077 story open world and firstperso...      1\n",
       "64189     masterchef | standup comedy by karunesh talwar      1\n",
       "64190                        how2 how to solve a mystery      0\n",
       "64191  kingdom hearts iii – square enix e3 showcase 2...      1\n",
       "64192                   trump advisor grovels to trudeau      0\n",
       "\n",
       "[64193 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ActualData.reset_index(drop = True, inplace = True)\n",
    "ActualData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d0ae0b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['No Punc Title', 'label'],\n",
       "    num_rows: 64193\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.from_pandas(ActualData)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d899433",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict\n",
    "# 80% train, 20% test + validation\n",
    "train_testvalid = dataset.train_test_split(test_size=0.2)\n",
    "# Split the 20% test + valid in half test, half valid\n",
    "test_valid = train_testvalid['test'].train_test_split(test_size=0.5)\n",
    "# gather everyone if you want to have a single DatasetDict\n",
    "train_test_valid_dataset = DatasetDict({\n",
    "    'train': train_testvalid['train'],\n",
    "    'test': test_valid['test'],\n",
    "    'valid': test_valid['train']})\n",
    "\n",
    "dataset = train_test_valid_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8709a1dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['No Punc Title', 'label'],\n",
       "        num_rows: 51354\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['No Punc Title', 'label'],\n",
       "        num_rows: 6420\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['No Punc Title', 'label'],\n",
       "        num_rows: 6419\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fda3032",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67e11acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"No Punc Title\"], truncation=True,padding=True, max_length = 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "831a95fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb8b30df962f4c67bf59edf6dc9a2683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "007c61519a804c87be128a31c3d35ac2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abbfe63e322a4caeaa07d936c19e52ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448b20e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2f31731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'No Punc Title': 'atlanta | season 2 official trailer hd | fx',\n",
       " 'label': 0,\n",
       " 'input_ids': [101,\n",
       "  5865,\n",
       "  1064,\n",
       "  2161,\n",
       "  1016,\n",
       "  2880,\n",
       "  9117,\n",
       "  10751,\n",
       "  1064,\n",
       "  23292,\n",
       "  102,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'token_type_ids': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset[\"test\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ccf7ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6731a81c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'No Punc Title': 'atlanta | season 2 official trailer hd | fx',\n",
       " 'label': 0,\n",
       " 'input_ids': [101,\n",
       "  5865,\n",
       "  1064,\n",
       "  2161,\n",
       "  1016,\n",
       "  2880,\n",
       "  9117,\n",
       "  10751,\n",
       "  1064,\n",
       "  23292,\n",
       "  102,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'token_type_ids': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset[\"test\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9aefeaa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Copy-and-paste the text below in your GitHub issue and FILL OUT the two last points.\n",
      "\n",
      "- `transformers` version: 4.18.0\n",
      "- Platform: Windows-10-10.0.19041-SP0\n",
      "- Python version: 3.8.8\n",
      "- Huggingface_hub version: 0.5.1\n",
      "- PyTorch version (GPU?): 1.11.0+cu113 (False)\n",
      "- Tensorflow version (GPU?): not installed (NA)\n",
      "- Flax version (CPU?/GPU?/TPU?): not installed (NA)\n",
      "- Jax version: not installed\n",
      "- JaxLib version: not installed\n",
      "- Using GPU in script?: <fill in>\n",
      "- Using distributed or parallel set-up in script?: <fill in>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! transformers-cli env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41609a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "  pred, labels = p\n",
    "  pred = np.argmax(pred,axis=1)\n",
    "  accuracy = accuracy_score(y_true = labels,y_pred =pred)\n",
    "  recall = recall_score(y_true = labels,y_pred =pred)\n",
    "  precision = precision_score(y_true = labels,y_pred =pred)\n",
    "  f1= f1_score(y_true = labels,y_pred =pred)\n",
    "  return { \"accuracy\": accuracy ,\"recall\": recall,\"precision\": precision,\"F1\":f1 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069c3a96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509bd99d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: No Punc Title, token_type_ids. If No Punc Title, token_type_ids are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "C:\\Users\\ddey4\\Anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 51354\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6420\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6075' max='6420' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6075/6420 9:15:01 < 31:31, 0.18 it/s, Epoch 1.89/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.633400</td>\n",
       "      <td>0.581725</td>\n",
       "      <td>0.695280</td>\n",
       "      <td>0.676438</td>\n",
       "      <td>0.752484</td>\n",
       "      <td>0.712438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.560400</td>\n",
       "      <td>0.515908</td>\n",
       "      <td>0.756348</td>\n",
       "      <td>0.858180</td>\n",
       "      <td>0.744310</td>\n",
       "      <td>0.797199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.508100</td>\n",
       "      <td>0.462545</td>\n",
       "      <td>0.785948</td>\n",
       "      <td>0.819933</td>\n",
       "      <td>0.801146</td>\n",
       "      <td>0.810430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.460600</td>\n",
       "      <td>0.455950</td>\n",
       "      <td>0.795139</td>\n",
       "      <td>0.912898</td>\n",
       "      <td>0.765270</td>\n",
       "      <td>0.832591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.427700</td>\n",
       "      <td>0.423319</td>\n",
       "      <td>0.819910</td>\n",
       "      <td>0.913735</td>\n",
       "      <td>0.794417</td>\n",
       "      <td>0.849909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.407300</td>\n",
       "      <td>0.384966</td>\n",
       "      <td>0.840941</td>\n",
       "      <td>0.898939</td>\n",
       "      <td>0.830111</td>\n",
       "      <td>0.863155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.349100</td>\n",
       "      <td>0.383134</td>\n",
       "      <td>0.846238</td>\n",
       "      <td>0.900893</td>\n",
       "      <td>0.836227</td>\n",
       "      <td>0.867357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.309800</td>\n",
       "      <td>0.375086</td>\n",
       "      <td>0.853248</td>\n",
       "      <td>0.883864</td>\n",
       "      <td>0.857530</td>\n",
       "      <td>0.870498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.296300</td>\n",
       "      <td>0.374776</td>\n",
       "      <td>0.854027</td>\n",
       "      <td>0.912898</td>\n",
       "      <td>0.839538</td>\n",
       "      <td>0.874682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.289900</td>\n",
       "      <td>0.385359</td>\n",
       "      <td>0.853248</td>\n",
       "      <td>0.917644</td>\n",
       "      <td>0.835536</td>\n",
       "      <td>0.874667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.292200</td>\n",
       "      <td>0.367661</td>\n",
       "      <td>0.859947</td>\n",
       "      <td>0.906756</td>\n",
       "      <td>0.851823</td>\n",
       "      <td>0.878431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.287000</td>\n",
       "      <td>0.368982</td>\n",
       "      <td>0.864465</td>\n",
       "      <td>0.908710</td>\n",
       "      <td>0.857030</td>\n",
       "      <td>0.882114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: No Punc Title, token_type_ids. If No Punc Title, token_type_ids are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6419\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-youtube-2-wmetrics\\checkpoint-500\n",
      "Configuration saved in distilbert-youtube-2-wmetrics\\checkpoint-500\\config.json\n",
      "Model weights saved in distilbert-youtube-2-wmetrics\\checkpoint-500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-youtube-2-wmetrics\\checkpoint-500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-youtube-2-wmetrics\\checkpoint-500\\special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: No Punc Title, token_type_ids. If No Punc Title, token_type_ids are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6419\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-youtube-2-wmetrics\\checkpoint-1000\n",
      "Configuration saved in distilbert-youtube-2-wmetrics\\checkpoint-1000\\config.json\n",
      "Model weights saved in distilbert-youtube-2-wmetrics\\checkpoint-1000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-youtube-2-wmetrics\\checkpoint-1000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-youtube-2-wmetrics\\checkpoint-1000\\special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: No Punc Title, token_type_ids. If No Punc Title, token_type_ids are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6419\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-youtube-2-wmetrics\\checkpoint-1500\n",
      "Configuration saved in distilbert-youtube-2-wmetrics\\checkpoint-1500\\config.json\n",
      "Model weights saved in distilbert-youtube-2-wmetrics\\checkpoint-1500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-youtube-2-wmetrics\\checkpoint-1500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-youtube-2-wmetrics\\checkpoint-1500\\special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: No Punc Title, token_type_ids. If No Punc Title, token_type_ids are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6419\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-youtube-2-wmetrics\\checkpoint-2000\n",
      "Configuration saved in distilbert-youtube-2-wmetrics\\checkpoint-2000\\config.json\n",
      "Model weights saved in distilbert-youtube-2-wmetrics\\checkpoint-2000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-youtube-2-wmetrics\\checkpoint-2000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-youtube-2-wmetrics\\checkpoint-2000\\special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: No Punc Title, token_type_ids. If No Punc Title, token_type_ids are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6419\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-youtube-2-wmetrics\\checkpoint-2500\n",
      "Configuration saved in distilbert-youtube-2-wmetrics\\checkpoint-2500\\config.json\n",
      "Model weights saved in distilbert-youtube-2-wmetrics\\checkpoint-2500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-youtube-2-wmetrics\\checkpoint-2500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-youtube-2-wmetrics\\checkpoint-2500\\special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: No Punc Title, token_type_ids. If No Punc Title, token_type_ids are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6419\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-youtube-2-wmetrics\\checkpoint-3000\n",
      "Configuration saved in distilbert-youtube-2-wmetrics\\checkpoint-3000\\config.json\n",
      "Model weights saved in distilbert-youtube-2-wmetrics\\checkpoint-3000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-youtube-2-wmetrics\\checkpoint-3000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-youtube-2-wmetrics\\checkpoint-3000\\special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: No Punc Title, token_type_ids. If No Punc Title, token_type_ids are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6419\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-youtube-2-wmetrics\\checkpoint-3500\n",
      "Configuration saved in distilbert-youtube-2-wmetrics\\checkpoint-3500\\config.json\n",
      "Model weights saved in distilbert-youtube-2-wmetrics\\checkpoint-3500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-youtube-2-wmetrics\\checkpoint-3500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-youtube-2-wmetrics\\checkpoint-3500\\special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: No Punc Title, token_type_ids. If No Punc Title, token_type_ids are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6419\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-youtube-2-wmetrics\\checkpoint-4000\n",
      "Configuration saved in distilbert-youtube-2-wmetrics\\checkpoint-4000\\config.json\n",
      "Model weights saved in distilbert-youtube-2-wmetrics\\checkpoint-4000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-youtube-2-wmetrics\\checkpoint-4000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-youtube-2-wmetrics\\checkpoint-4000\\special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: No Punc Title, token_type_ids. If No Punc Title, token_type_ids are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6419\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-youtube-2-wmetrics\\checkpoint-4500\n",
      "Configuration saved in distilbert-youtube-2-wmetrics\\checkpoint-4500\\config.json\n",
      "Model weights saved in distilbert-youtube-2-wmetrics\\checkpoint-4500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-youtube-2-wmetrics\\checkpoint-4500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-youtube-2-wmetrics\\checkpoint-4500\\special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: No Punc Title, token_type_ids. If No Punc Title, token_type_ids are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6419\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-youtube-2-wmetrics\\checkpoint-5000\n",
      "Configuration saved in distilbert-youtube-2-wmetrics\\checkpoint-5000\\config.json\n",
      "Model weights saved in distilbert-youtube-2-wmetrics\\checkpoint-5000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-youtube-2-wmetrics\\checkpoint-5000\\tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in distilbert-youtube-2-wmetrics\\checkpoint-5000\\special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: No Punc Title, token_type_ids. If No Punc Title, token_type_ids are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6419\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-youtube-2-wmetrics\\checkpoint-5500\n",
      "Configuration saved in distilbert-youtube-2-wmetrics\\checkpoint-5500\\config.json\n",
      "Model weights saved in distilbert-youtube-2-wmetrics\\checkpoint-5500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-youtube-2-wmetrics\\checkpoint-5500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-youtube-2-wmetrics\\checkpoint-5500\\special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: No Punc Title, token_type_ids. If No Punc Title, token_type_ids are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6419\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-youtube-2-wmetrics\\checkpoint-6000\n",
      "Configuration saved in distilbert-youtube-2-wmetrics\\checkpoint-6000\\config.json\n",
      "Model weights saved in distilbert-youtube-2-wmetrics\\checkpoint-6000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-youtube-2-wmetrics\\checkpoint-6000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-youtube-2-wmetrics\\checkpoint-6000\\special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"distilbert-youtube-2-wmetrics\",\n",
    "    learning_rate=2e-5,\n",
    "    evaluation_strategy= \"steps\",\n",
    "    eval_steps = 500,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"valid\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics = compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e03c28b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: No Punc Title, token_type_ids. If No Punc Title, token_type_ids are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "C:\\Users\\ddey4\\Anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 51354\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6420\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6420' max='6420' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6420/6420 9:40:50, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.633400</td>\n",
       "      <td>0.581725</td>\n",
       "      <td>0.695280</td>\n",
       "      <td>0.676438</td>\n",
       "      <td>0.752484</td>\n",
       "      <td>0.712438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.560400</td>\n",
       "      <td>0.515908</td>\n",
       "      <td>0.756348</td>\n",
       "      <td>0.858180</td>\n",
       "      <td>0.744310</td>\n",
       "      <td>0.797199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.508100</td>\n",
       "      <td>0.462545</td>\n",
       "      <td>0.785948</td>\n",
       "      <td>0.819933</td>\n",
       "      <td>0.801146</td>\n",
       "      <td>0.810430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.460600</td>\n",
       "      <td>0.455950</td>\n",
       "      <td>0.795139</td>\n",
       "      <td>0.912898</td>\n",
       "      <td>0.765270</td>\n",
       "      <td>0.832591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.427700</td>\n",
       "      <td>0.423319</td>\n",
       "      <td>0.819910</td>\n",
       "      <td>0.913735</td>\n",
       "      <td>0.794417</td>\n",
       "      <td>0.849909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.407300</td>\n",
       "      <td>0.384966</td>\n",
       "      <td>0.840941</td>\n",
       "      <td>0.898939</td>\n",
       "      <td>0.830111</td>\n",
       "      <td>0.863155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.349100</td>\n",
       "      <td>0.383134</td>\n",
       "      <td>0.846238</td>\n",
       "      <td>0.900893</td>\n",
       "      <td>0.836227</td>\n",
       "      <td>0.867357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.309800</td>\n",
       "      <td>0.375086</td>\n",
       "      <td>0.853248</td>\n",
       "      <td>0.883864</td>\n",
       "      <td>0.857530</td>\n",
       "      <td>0.870498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.296300</td>\n",
       "      <td>0.374776</td>\n",
       "      <td>0.854027</td>\n",
       "      <td>0.912898</td>\n",
       "      <td>0.839538</td>\n",
       "      <td>0.874682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.289900</td>\n",
       "      <td>0.385359</td>\n",
       "      <td>0.853248</td>\n",
       "      <td>0.917644</td>\n",
       "      <td>0.835536</td>\n",
       "      <td>0.874667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.292200</td>\n",
       "      <td>0.367661</td>\n",
       "      <td>0.859947</td>\n",
       "      <td>0.906756</td>\n",
       "      <td>0.851823</td>\n",
       "      <td>0.878431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.287000</td>\n",
       "      <td>0.368982</td>\n",
       "      <td>0.864465</td>\n",
       "      <td>0.908710</td>\n",
       "      <td>0.857030</td>\n",
       "      <td>0.882114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: No Punc Title, token_type_ids. If No Punc Title, token_type_ids are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6419\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-youtube-2-wmetrics\\checkpoint-500\n",
      "Configuration saved in distilbert-youtube-2-wmetrics\\checkpoint-500\\config.json\n",
      "Model weights saved in distilbert-youtube-2-wmetrics\\checkpoint-500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-youtube-2-wmetrics\\checkpoint-500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-youtube-2-wmetrics\\checkpoint-500\\special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: No Punc Title, token_type_ids. If No Punc Title, token_type_ids are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6419\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-youtube-2-wmetrics\\checkpoint-1000\n",
      "Configuration saved in distilbert-youtube-2-wmetrics\\checkpoint-1000\\config.json\n",
      "Model weights saved in distilbert-youtube-2-wmetrics\\checkpoint-1000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-youtube-2-wmetrics\\checkpoint-1000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-youtube-2-wmetrics\\checkpoint-1000\\special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: No Punc Title, token_type_ids. If No Punc Title, token_type_ids are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6419\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-youtube-2-wmetrics\\checkpoint-1500\n",
      "Configuration saved in distilbert-youtube-2-wmetrics\\checkpoint-1500\\config.json\n",
      "Model weights saved in distilbert-youtube-2-wmetrics\\checkpoint-1500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-youtube-2-wmetrics\\checkpoint-1500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-youtube-2-wmetrics\\checkpoint-1500\\special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: No Punc Title, token_type_ids. If No Punc Title, token_type_ids are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6419\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-youtube-2-wmetrics\\checkpoint-2000\n",
      "Configuration saved in distilbert-youtube-2-wmetrics\\checkpoint-2000\\config.json\n",
      "Model weights saved in distilbert-youtube-2-wmetrics\\checkpoint-2000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-youtube-2-wmetrics\\checkpoint-2000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-youtube-2-wmetrics\\checkpoint-2000\\special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: No Punc Title, token_type_ids. If No Punc Title, token_type_ids are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6419\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-youtube-2-wmetrics\\checkpoint-2500\n",
      "Configuration saved in distilbert-youtube-2-wmetrics\\checkpoint-2500\\config.json\n",
      "Model weights saved in distilbert-youtube-2-wmetrics\\checkpoint-2500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-youtube-2-wmetrics\\checkpoint-2500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-youtube-2-wmetrics\\checkpoint-2500\\special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: No Punc Title, token_type_ids. If No Punc Title, token_type_ids are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6419\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-youtube-2-wmetrics\\checkpoint-3000\n",
      "Configuration saved in distilbert-youtube-2-wmetrics\\checkpoint-3000\\config.json\n",
      "Model weights saved in distilbert-youtube-2-wmetrics\\checkpoint-3000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-youtube-2-wmetrics\\checkpoint-3000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-youtube-2-wmetrics\\checkpoint-3000\\special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: No Punc Title, token_type_ids. If No Punc Title, token_type_ids are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6419\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-youtube-2-wmetrics\\checkpoint-3500\n",
      "Configuration saved in distilbert-youtube-2-wmetrics\\checkpoint-3500\\config.json\n",
      "Model weights saved in distilbert-youtube-2-wmetrics\\checkpoint-3500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-youtube-2-wmetrics\\checkpoint-3500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-youtube-2-wmetrics\\checkpoint-3500\\special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: No Punc Title, token_type_ids. If No Punc Title, token_type_ids are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6419\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-youtube-2-wmetrics\\checkpoint-4000\n",
      "Configuration saved in distilbert-youtube-2-wmetrics\\checkpoint-4000\\config.json\n",
      "Model weights saved in distilbert-youtube-2-wmetrics\\checkpoint-4000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-youtube-2-wmetrics\\checkpoint-4000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-youtube-2-wmetrics\\checkpoint-4000\\special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: No Punc Title, token_type_ids. If No Punc Title, token_type_ids are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6419\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-youtube-2-wmetrics\\checkpoint-4500\n",
      "Configuration saved in distilbert-youtube-2-wmetrics\\checkpoint-4500\\config.json\n",
      "Model weights saved in distilbert-youtube-2-wmetrics\\checkpoint-4500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-youtube-2-wmetrics\\checkpoint-4500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-youtube-2-wmetrics\\checkpoint-4500\\special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: No Punc Title, token_type_ids. If No Punc Title, token_type_ids are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6419\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-youtube-2-wmetrics\\checkpoint-5000\n",
      "Configuration saved in distilbert-youtube-2-wmetrics\\checkpoint-5000\\config.json\n",
      "Model weights saved in distilbert-youtube-2-wmetrics\\checkpoint-5000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-youtube-2-wmetrics\\checkpoint-5000\\tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in distilbert-youtube-2-wmetrics\\checkpoint-5000\\special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: No Punc Title, token_type_ids. If No Punc Title, token_type_ids are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6419\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-youtube-2-wmetrics\\checkpoint-5500\n",
      "Configuration saved in distilbert-youtube-2-wmetrics\\checkpoint-5500\\config.json\n",
      "Model weights saved in distilbert-youtube-2-wmetrics\\checkpoint-5500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-youtube-2-wmetrics\\checkpoint-5500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-youtube-2-wmetrics\\checkpoint-5500\\special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: No Punc Title, token_type_ids. If No Punc Title, token_type_ids are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6419\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to distilbert-youtube-2-wmetrics\\checkpoint-6000\n",
      "Configuration saved in distilbert-youtube-2-wmetrics\\checkpoint-6000\\config.json\n",
      "Model weights saved in distilbert-youtube-2-wmetrics\\checkpoint-6000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-youtube-2-wmetrics\\checkpoint-6000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-youtube-2-wmetrics\\checkpoint-6000\\special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from distilbert-youtube-2-wmetrics\\checkpoint-5500 (score: 0.3676605820655823).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6420, training_loss=0.3928717699377708, metrics={'train_runtime': 34858.4571, 'train_samples_per_second': 2.946, 'train_steps_per_second': 0.184, 'total_flos': 1426087611795912.0, 'train_loss': 0.3928717699377708, 'epoch': 2.0})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"distilbert-youtube-2-wmetrics\",\n",
    "    learning_rate=2e-5,\n",
    "    evaluation_strategy= \"steps\",\n",
    "    eval_steps = 500,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"valid\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics = compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b7313df",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= [500,1000,1500,2000,2500,3000,3500,4000,4500,5000,5500,6000]\n",
    "tloss = [ 0.633400, 0.560400 ,0.508100 , 0.460600, 0.427700, 0.407300 , 0.349100 ,0.309800, 0.296300, 0.289900,0.292200 ,0.287000]\n",
    "vloss =[0.581725, 0.515908 , 0.462545 , 0.455950 , 0.423319 , 0.384966, 0.383134 , 0.375086  ,0.374776 , 0.385359 , 0.367661, 0.368982]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54dc0c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(x,tloss,label=\"Train loss\") #Plotting training loss valies manually logged above \n",
    "plt.plot(x,vloss,label=\"Valid loss\") #Plotting Validation loss valies manually logged above\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82c04627",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer.push_to_hub(\"End of training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c25a8959",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: No Punc Title, token_type_ids. If No Punc Title, token_type_ids are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 6420\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='402' max='402' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [402/402 05:41]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ----- 3. Predict -----#\n",
    "# Load test data\n",
    "# tokenized_dataset[\"valid\"] - incorrectly used test before hence validation here \n",
    "\n",
    "# Load trained model\n",
    "#model_path = \"output/checkpoint-50000\"\n",
    "#model = BertForSequenceClassification.from_pretrained(model_path, num_labels=2)\n",
    "\n",
    "# Define test trainer\n",
    "#test_trainer = Trainer(model)\n",
    "\n",
    "# Make prediction\n",
    "raw_pred,_,_ = trainer.predict(tokenized_dataset[\"test\"])\n",
    "\n",
    "# Preprocess raw predictions\n",
    "y_pred2 = np.argmax(raw_pred, axis=1)\n",
    "y_test = tokenized_dataset[\"test\"][\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0a2dbecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  86.51090342679127\n",
      "F1 Score  88.31939573779337\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Metrics\n",
    "print(\"Accuracy \",metrics.accuracy_score(y_test, y_pred2)*100)\n",
    "print(\"F1 Score \",metrics.f1_score(y_test, y_pred2)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40f05d6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(91.68, 0.5, 'predicted label')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Confustion Matrix heat map\n",
    "mat = confusion_matrix(y_test, y_pred2)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "            )\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df4b490f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.82      0.84      2785\n",
      "           1       0.87      0.90      0.88      3635\n",
      "\n",
      "    accuracy                           0.87      6420\n",
      "   macro avg       0.86      0.86      0.86      6420\n",
      "weighted avg       0.87      0.87      0.86      6420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification Report\n",
    "print(metrics.classification_report(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3cc16c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49a7d19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
